# 目前已完成的工作
1. 爬虫——豆瓣网站，数据量共40000余条，使用python-requests网络爬虫，提取网站json数据，存入本地mongoDB数据库
MongoDB命令行：
脚本启动 
mongo
show dbs
use ****
show collections
db.back_up.find()

2. 自然语言处理
正则表达式去除符号表情英文、jieba分词、去除停用词、去除平凡词、独特词
此处没有太多的东西

3. 朴素贝叶斯
手动实现已解决，目前就只有数据量的限制
使用工具包sklearn-NB 也实现了朴素贝叶斯的分类效果
TF-IDF 词频-逆文本频率
TF表示一个词出现的词频
而IDF表示一个词在整个文本中出现的频数，也就是有多少个文档包含这个词
当使用sklearn工具时，概率不是很高，因为出现了欠拟合问题，感觉是因为数据量少，然后特征数少，造成不能很好的拟合数据
解释好召回率、准确率、F值

4. 支持向量机
手动推导了数学公式
只有借助工具包实现，因为手动实现过于繁琐
不过借助于工具实现的话，数据量有所限制，不能太多，不然会报内存错误

___

# 未完成的工作
1. 使用卷积神经网络对文本的情感进行分析
2. 特征选择的方法实现：互信息、卡方
3. 目前实现的都是基于词袋模型的词向量表示，后续考虑将word2Vec应用到词向量空间中，比对一下效果